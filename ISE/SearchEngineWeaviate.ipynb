{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EMbeDS-education/ComputingDataAnalysisModeling20242025/blob/main/ISE/SearchEngineWeaviate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weaviate as a Search Engine"
      ],
      "metadata": {
        "id": "euSpBGPyWT2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##################### TO START\n",
        "\n",
        "Please download your COHERE key to vectorize texts from\n",
        "\n",
        "https://dashboard.cohere.com/api-keys.\n",
        "\n",
        "Then load your key in the \"secrets\" of Colab, here to the left, by clicking on the key icon, and storing as \"COHERE_APIKEY\".\n",
        "\n",
        "You find all the documentation of Weaviate in:\n",
        "\n",
        "https://weaviate.io/developers/weaviate\n",
        "\n",
        "###########################################################"
      ],
      "metadata": {
        "id": "qPZG5m1mBNBo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehWhrBsKVeaI",
        "outputId": "5403c722-947b-448e-a609-0155d2bcc653",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.11.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.28.1)\n",
            "Collecting validators==0.34.0 (from weaviate-client)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (2.10.6)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.71.0)\n",
            "Collecting grpcio-tools<2.0.0,>=1.66.2 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.71.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.11/dist-packages (from grpcio-health-checking<2.0.0,>=1.66.2->weaviate-client) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools<2.0.0,>=1.66.2->weaviate-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\n",
            "Downloading weaviate_client-4.11.3-py3-none-any.whl (353 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.9/353.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.71.0-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, grpcio-tools, grpcio-health-checking, authlib, weaviate-client\n",
            "Successfully installed authlib-1.3.1 grpcio-health-checking-1.71.0 grpcio-tools-1.71.0 validators-0.34.0 weaviate-client-4.11.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U weaviate-client\n",
        "import weaviate\n",
        "import weaviate.classes.config as wc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Weaviate client\n",
        "\n",
        "import weaviate\n",
        "from weaviate.classes.query import MetadataQuery\n",
        "from weaviate.classes.config import Configure, Property, DataType, Tokenization\n",
        "from weaviate.classes.query import Filter\n",
        "\n",
        "client = weaviate.connect_to_embedded()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfAKTpq7ZEvq",
        "outputId": "ea75d52f-9b4c-400f-f592-ff7a8cb7f9a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Binary /root/.cache/weaviate-embedded did not exist. Downloading binary from https://github.com/weaviate/weaviate/releases/download/v1.26.6/weaviate-v1.26.6-Linux-amd64.tar.gz\n",
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/EMbeDS-education/ComputingDataAnalysisModeling20242025/refs/heads/main/ISE/data/5articles.json\n",
        "import json\n",
        "\n",
        "with open(\"5articles.json\", 'r') as f:\n",
        "  articles = json.load(f)\n",
        "\n",
        "articles[0]"
      ],
      "metadata": {
        "id": "CM6M1Nk4iJaM",
        "outputId": "0ae73f75-2d2a-43e9-98ff-bb45ad61757e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-31 06:11:29--  https://raw.githubusercontent.com/EMbeDS-education/ComputingDataAnalysisModeling20242025/refs/heads/main/ISE/data/5articles.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12566 (12K) [text/plain]\n",
            "Saving to: ‘5articles.json’\n",
            "\n",
            "5articles.json      100%[===================>]  12.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-31 06:11:29 (28.1 MB/s) - ‘5articles.json’ saved [12566/12566]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'American Airlines orders 60 Overture supersonic jets',\n",
              " 'maintext': \"The revival of supersonic passenger travel, thought to be long dead with the demise of Concorde nearly two decades ago, could be about to take wing as American Airlines has put in an order for 60 aircraft capable of flying at 1.7 times the speed of sound. \\nBoom is a start-up based in Denver, Colorado, whose development of Overture, an ultra-fast successor to Concorde that seats 65 to 88 passengers, is so advanced that it showed off designs at last month's Farnborough air show.\",\n",
              " 'date': '2022-08-18',\n",
              " 'source': 'The New York Times'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a simple collection that has four fields of type TEXT and DATE, call it \"TestCollection\".\n",
        "\n",
        "**TOKENIZATION OPTIONS**\n",
        "* word: alphanumeric, lowercased tokens, with stopwords filtering (default tokenizer for Weaviate)\n",
        "* lowercase: lowercased tokens\n",
        "* whitespace: whitespace-separated, case-sensitive tokens\n",
        "* field: the entire value of the property is treated as a single token"
      ],
      "metadata": {
        "id": "IOwPipiL2Hu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[All property types](https://weaviate.io/developers/weaviate/config-refs/datatypes)"
      ],
      "metadata": {
        "id": "CY_I5yrgGBzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all() # To remove anything created before, if any\n",
        "\n",
        "client.collections.create(\n",
        "    name=\"TestCollection\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Just typing \"wc.DataType.\" you can explore other data types..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgtV0ZcfaFLK",
        "outputId": "ca751061-f265-4d83-b8f7-1cae2d9de05a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x78edc86f1550>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATE A TEST COLLECTION**\n",
        "\n",
        "Now we create the collection of name \"TestCollection\" and we insert the \"articles\" in it"
      ],
      "metadata": {
        "id": "iG_xXKqf8ADR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timezone, datetime\n",
        "\n",
        "documents = client.collections.get(\"TestCollection\")\n",
        "\n",
        "for doc in articles:\n",
        "    documents.data.insert({\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"title\": doc[\"title\"],\n",
        "        \"source\": doc[\"source\"],\n",
        "        \"date\": datetime.strptime(doc[\"date\"], \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "sXQi9K3peTUr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ITERATE over all documents in the collection**\n",
        "\n",
        "Notice that it is a \"map\" so that the listing is not necessarily in the order in which they have been inserted"
      ],
      "metadata": {
        "id": "uGS1C5Be8Dk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the elements\n",
        "for i, doc in enumerate(documents.iterator()):\n",
        "  print(doc.uuid, \" - \", doc.properties[\"title\"], \" - \", doc.properties[\"source\"], \" - \", doc.properties[\"date\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGxnrxb4eVou",
        "outputId": "57cc50c6-6234-4203-a4d2-9b9e8efaf7e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10b557dc-09e0-48c0-8a75-801d3e9b588c  -  Conte: 'Chelsea are not in the race to sign Sanchez'  -  The Herald-ir  -  2018-01-23 00:00:00+00:00\n",
            "81ead317-3ca0-4f47-ae64-35fe98d927a5  -  Gunman opens fire on car just metres from scene of Hamid Sanambar murder  -  The Herald-ir  -  2019-06-07 00:00:00+00:00\n",
            "9f9bdd9c-41c8-4c8c-82af-8b680584378a  -  Leclerc dedicates win to Hubert  -  The Herald-ir  -  2019-09-01 00:00:00+00:00\n",
            "b3fb4b46-b6a5-44f3-b104-b72a46cb4e60  -  'One-punch killer's sentence will make others think twice'  -  The Herald-ir  -  2019-06-29 00:00:00+00:00\n",
            "fa4c198b-30a9-4af9-8496-a426667a8395  -  American Airlines orders 60 Overture supersonic jets  -  The New York Times  -  2022-08-18 00:00:00+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUERYING THE COLLECTION**\n",
        "\n",
        "Let's try some simple queries, **bm25** is the sparse vectorization of texts (better than TFIDF) that Weaviate adopts.\n",
        "\n",
        "Notice that it lowercases the parsed tokens, but it does not stem them. This is on the roadmap of features that Weaviate plans to support in the future."
      ],
      "metadata": {
        "id": "KxWBLZ_p8H4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"race\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n",
        "    print(\"query term occurs: \", o.properties[\"maintext\"].count(\"race\"), \" in maintext and \", o.properties[\"title\"].count(\"race\"), \" in title\\n\")"
      ],
      "metadata": {
        "id": "eTcpqOrchF3P",
        "outputId": "878b2d70-5e7d-408e-adf5-40c1bbf04776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.18 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "query term occurs:  1  in maintext and  1  in title\n",
            "\n",
            "0.46 - Leclerc dedicates win to Hubert\n",
            "query term occurs:  3  in maintext and  0  in title\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing is induced also by -\n",
        "\n",
        "query = \"punch\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "AOrhYY5xnFtd",
        "outputId": "8e304238-8bd4-4cda-a725-eca94e74c941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7 - 'One-punch killer's sentence will make others think twice'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing is lowercase\n",
        "\n",
        "query = \"sanchez\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "gypOwhconh99",
        "outputId": "b0c9808d-e16a-4512-d419-b2f5829b0485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.77 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It is a FIELD parsing, so it does not find \"The New York Times\" in article on \"American Airlines\"\n",
        "\n",
        "query = \"The\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "ME3EcWKnnM7M",
        "outputId": "236e5c7e-3428-4abc-9be9-9038522473ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.97 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the stopwords are not present by assuming English in field \"maintext\" but they are include in the field \"title\"\n",
        "\n",
        "query = \"the\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "WwXKRsdmoQU7",
        "outputId": "8b513793-b6e4-4eeb-f2a6-6a281727b5ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.97 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHANGING STOPWORDS**\n",
        "\n",
        "Say that you now want to consider some words as \"stopwords\", that the system does not consider as such by default\n",
        "\n",
        "documents.config.update(inverted_index_config=wc.Reconfigure.inverted_index(stopwords_additions=[\"victory\"]))\n",
        "\n"
      ],
      "metadata": {
        "id": "5E7rUP8q7zmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEARCH ON A SPECIFIC PROPERTY**"
      ],
      "metadata": {
        "id": "387lhTR4omfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# maintext == is tokenized as WORD and thus stopwords are removed (hence, \"will\" is removed)\n",
        "\n",
        "response = documents.query.bm25(\n",
        "    query=\"will\",\n",
        "    query_properties=[\"maintext\"], # this is the line to add\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n"
      ],
      "metadata": {
        "id": "akK8VFJjok6D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# title == is tokenized as LOWERCASE and thus stopwords are NOT removed\n",
        "\n",
        "\n",
        "response = documents.query.bm25(\n",
        "    query=\"will\",\n",
        "    query_properties=[\"title\"], # this is the line to add\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n",
        "    print(\"query term occurs: \", o.properties[\"title\"].count(\"will\"), \"\\n\")"
      ],
      "metadata": {
        "id": "03IKciyNKWwn",
        "outputId": "76de1b9b-eeed-4d86-ca01-380f48b4adf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.65 - 'One-punch killer's sentence will make others think twice'\n",
            "query term occurs:  1 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AFTER FIELD BOOSTING**\n",
        "\n",
        "The score is not twice. It applies some normalization and other formulas."
      ],
      "metadata": {
        "id": "XKDIORwYpKAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BEFORE BOOSTING:\\n\")\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title\", \"maintext\"],\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n",
        "\n",
        "print(\"\\n\\nAFTER BOOSTING:\\n\")\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title^2\", \"maintext\"],\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMXZT4hh9qgy",
        "outputId": "d25ebaf4-2168-4cb7-a745-31b6a7347d62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE BOOSTING:\n",
            "\n",
            "1.27 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n",
            "\n",
            "\n",
            "AFTER BOOSTING:\n",
            "\n",
            "1.43 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APPLY FIELD FILTERING**\n",
        "\n",
        "We can further filter the results by applying some conditions on the fields."
      ],
      "metadata": {
        "id": "PyTBGhiYqMao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title^2\", \"maintext\"],\n",
        "    filters=Filter.by_property(\"title\").contains_any([\"Leclerc\", \"formula\"]),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "M4i6SecEqQxC",
        "outputId": "e73bd2c4-dd46-40c2-d9c9-7f22f4975116",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FILTERING BY DATE or MANY PROPERTIES**"
      ],
      "metadata": {
        "id": "Rgf96h1TrOWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BEFORE FILTERING BY DATE:\\n\")\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n",
        "\n",
        "print(\"\\n\\nAFTER FILTERING BY DATE:\\n\")\n",
        "reference_date = datetime.strptime(\"2018-08-15\", \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    filters=Filter.by_property(\"date\").greater_or_equal(reference_date),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n",
        "\n",
        "\n",
        "print(\"\\n\\nAPPLY MANY FILTERS OVER MANY PROPERTIES:\\n\")\n",
        "reference_date = datetime.strptime(\"2018-08-15\", \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    filters=( ## use of &, but also |\n",
        "        Filter.by_property(\"date\").greater_or_equal(reference_date) &\n",
        "        Filter.by_property(\"title\").contains_any([\"won\", \"formula\"])\n",
        "        ),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR4i3bKfJ9eJ",
        "outputId": "6dac080d-2ba0-4a75-a9d6-f78e3b5f143c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE FILTERING BY DATE:\n",
            "\n",
            "1.18 - Conte: 'Chelsea are not in the race to sign Sanchez' (2018-01-23 00:00:00+00:00)\n",
            "0.46 - Leclerc dedicates win to Hubert (2019-09-01 00:00:00+00:00)\n",
            "\n",
            "\n",
            "AFTER FILTERING BY DATE:\n",
            "\n",
            "0.46 - Leclerc dedicates win to Hubert (2019-09-01 00:00:00+00:00)\n",
            "\n",
            "\n",
            "APPLY MANY FILTERS OVER MANY PROPERTIES:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VECTORIZATION:: DENSE EMBEDDINGS**\n",
        "\n",
        "Some advanced features, let's try some vectorized queries. Let's assume we want to find all articles that are \"related to sport\". In this current collection, \"sport\" is not present as a word in any title or maintext."
      ],
      "metadata": {
        "id": "-0oumORCKS3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The term \"sport\" does not occur and so BM25 does not return any result\n",
        "\n",
        "response = documents.query.bm25(query=\"sport\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "uzryepW_KWFV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfortunately, we cannot use all the vectorizer modules that are present in Weaviate.\n",
        "# Here is a list of the ones that are available\n",
        "client.get_meta()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW9aIbtBRG80",
        "outputId": "3de34a8c-0b85-42f2-e01e-f725b5634924"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hostname': 'http://127.0.0.1:8079',\n",
              " 'modules': {'generative-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "   'name': 'Generative Search - OpenAI'},\n",
              "  'qna-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "   'name': 'OpenAI Question & Answering Module'},\n",
              "  'ref2vec-centroid': {},\n",
              "  'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/',\n",
              "   'name': 'Reranker - Cohere'},\n",
              "  'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/',\n",
              "   'name': 'Cohere Module'},\n",
              "  'text2vec-huggingface': {'documentationHref': 'https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task',\n",
              "   'name': 'Hugging Face Module'},\n",
              "  'text2vec-openai': {'documentationHref': 'https://platform.openai.com/docs/guides/embeddings/what-are-embeddings',\n",
              "   'name': 'OpenAI Module'}},\n",
              " 'version': '1.26.6'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use COHERE as a textual vectorizer [https://dashboard.cohere.com/api-keys](https://dashboard.cohere.com/api-keys). As we can see, using colab we have only a few options for vectorization (openai, cohere, huggingface). Additionally, only one generation model is available (openai).\n",
        "Cohere provides free sample apis. OpenAI does not.\n",
        "\n",
        "At this link you find how to integrate MODELS [https://weaviate.io/developers/weaviate/model-providers](https://weaviate.io/developers/weaviate/model-providers)"
      ],
      "metadata": {
        "id": "2eb-2ivBTN8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Remember that you need to create a KEY !!!!\n",
        "from google.colab import userdata\n",
        "\n",
        "client.close()\n",
        "cohere_key = userdata.get('COHERE_APIKEY') # MAKE SURE YOU CREATED A KEY\n",
        "headers = {\n",
        "    \"X-Cohere-Api-Key\": cohere_key,\n",
        "}\n",
        "client = weaviate.connect_to_embedded(headers=headers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n67v0q_ETPvy",
        "outputId": "8872da10-3aea-4ced-cd90-740f0b2b795f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 2383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATE A VECTOR DB**\n"
      ],
      "metadata": {
        "id": "Df7kq_CvAljh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "client.collections.create(\n",
        "    name=\"TestVectorizer\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ],\n",
        "    vectorizer_config=[\n",
        "        Configure.NamedVectors.text2vec_cohere(\n",
        "            name=\"maintext_vector\",\n",
        "            source_properties=[\"maintext\"]\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wudqBaSsKtkJ",
        "outputId": "d8b98d55-f5aa-421b-c2d4-ef31f3eb3809"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x78edc8278590>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timezone, datetime\n",
        "\n",
        "documents = client.collections.get(\"TestVectorizer\")\n",
        "\n",
        "for doc in articles:\n",
        "    documents.data.insert({\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"title\": doc[\"title\"],\n",
        "        \"source\": doc[\"source\"],\n",
        "        \"date\": datetime.strptime(doc[\"date\"], \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "KtFZv0nSMLDO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'sport'\\n\")\n",
        "response = documents.query.bm25(query=\"sport\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4490f833-41ba-4704-b552-e0ebb01177e7",
        "id": "e3JPi_1RPNos"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'sport'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure vector search (ordered by increasing distance): 'sport'\\n\")\n",
        "# NOTE THAT WE ALSO NEED THE PARAMETER DISTANCE\n",
        "response = documents.query.near_text(query=\"sport\", return_metadata=MetadataQuery(score=True, distance=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} (score is {})\".format(round(o.metadata.distance*100)/100, o.properties[\"title\"], round(o.metadata.score*100)/100))"
      ],
      "metadata": {
        "id": "eVLWxgqCPNHP",
        "outputId": "b578bfba-3ed7-49d7-9a34-d4aaa13dee1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure vector search (ordered by increasing distance): 'sport'\n",
            "\n",
            "0.6 - Leclerc dedicates win to Hubert (score is 0.0)\n",
            "0.61 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder (score is 0.0)\n",
            "0.65 - Conte: 'Chelsea are not in the race to sign Sanchez' (score is 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HYBRID SEARCH**\n",
        "\n",
        "Let us consider a query that admits results for both syntactic and vectorized search"
      ],
      "metadata": {
        "id": "YRXiT32tM_Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'race'\\n\")\n",
        "response = documents.query.bm25(query=\"race\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4uaK6uMN2Uk",
        "outputId": "44a4e01d-84df-46c5-8608-fefdb5b5dfa8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'race'\n",
            "\n",
            "1.18 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.46 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure vector search (ordered by increasing distance): 'race'\\n\")\n",
        "# NOTE THAT WE ALSO NEED THE PARAMETER DISTANCE\n",
        "response = documents.query.near_text(query=\"race\", return_metadata=MetadataQuery(score=True, distance=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} (score is {})\".format(round(o.metadata.distance*100)/100, o.properties[\"title\"], round(o.metadata.score*100)/100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnPc546bOJRn",
        "outputId": "74d5d52c-c8bd-45c7-930c-502b8e201386"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure vector search (ordered by increasing distance): 'race'\n",
            "\n",
            "0.6 - Leclerc dedicates win to Hubert (score is 0.0)\n",
            "0.61 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder (score is 0.0)\n",
            "0.69 - Conte: 'Chelsea are not in the race to sign Sanchez' (score is 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = syntactic, 1 = vectorized\n",
        "print(\"hybrid search (ordered by decreasing score): 'race'\")\n",
        "response = documents.query.hybrid(query=\"race\", alpha=0.5, return_metadata=MetadataQuery(score=True, explain_score=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} [{}]\".format(round(o.metadata.score*100)/100, o.properties[\"title\"],  o.metadata.explain_score.strip().replace(\"\\n\", '')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpWxVaoXRLrh",
        "outputId": "81eabc7a-b833-494f-c44b-7c53a0c78647"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hybrid search (ordered by decreasing score): 'race'\n",
            "0.6 - Conte: 'Chelsea are not in the race to sign Sanchez' [Hybrid (Result Set keyword,bm25) Document f647ade1-78a3-4209-9e29-060518c6211a: original score 1.1806082, normalized score: 0.5 - Hybrid (Result Set vector,hybridVector) Document f647ade1-78a3-4209-9e29-060518c6211a: original score 0.3125717, normalized score: 0.10040327]\n",
            "0.5 - Leclerc dedicates win to Hubert [Hybrid (Result Set keyword,bm25) Document 6d2b5faa-6d32-4c54-ad0e-78c45f888d27: original score 0.46220398, normalized score: 0 - Hybrid (Result Set vector,hybridVector) Document 6d2b5faa-6d32-4c54-ad0e-78c45f888d27: original score 0.39786828, normalized score: 0.5]\n",
            "0.46 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder [Hybrid (Result Set vector,hybridVector) Document 30365daa-9be1-44f8-9bd7-24fc74419982: original score 0.38972962, normalized score: 0.46187207]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Description of how scoring works](https://weaviate.io/developers/weaviate/concepts/search/hybrid-search)"
      ],
      "metadata": {
        "id": "ivXz0Sg1K9FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A new method, RAG\n",
        "\n",
        "RAG stands for Retrieval Augmented Generation. This is a recent trend in Information Retrieval that aims at reducing the problem of \"hallucinations\" for Large Language Model generation, and returns better answers based on local document archives.\n",
        "- Traditional queries go as follows: the user makes a query to a search engine; the search engine returns, in some predefined format, the answer to that query.\n",
        "- LLM queries: the user makes a query to a Large Language Model (LLM); the LLM creates an answer based on the (often unspecified) training data that was originally used to train it. The LLM often hallucinates, returing wrong answers.\n",
        "- RAG: the user makes a query to a search engine; the search engine runs the query and gets its results. Before returning the results to the user, they are sent to a LLM to \"process\" and generate a textual response that is more convenient to read for the user, but (ideally) does not contain hallucinated information because they use precomputed (retrieved) results."
      ],
      "metadata": {
        "id": "6TXPYna2acie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://weaviate.io/developers/weaviate/model-providers"
      ],
      "metadata": {
        "id": "LNdJHCnjxWRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GENERATIVE AI with OPENAI GPT-4**\n",
        "\n",
        "Now let's try to include some generative AI prompts to this query (let's add context to the entities in the news, or let's translate them in Italian).\n",
        "Note that this query will only work for those who have an openai paid module."
      ],
      "metadata": {
        "id": "EpjAkCt1SXmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.close()\n",
        "\n",
        "cohere_key = userdata.get('COHERE_APIKEY')\n",
        "openai_key = userdata.get(\"OPEN_APIKEY2\")\n",
        "headers = {\n",
        "    \"X-Cohere-Api-Key\": cohere_key,\n",
        "    \"X-OpenAI-Api-Key\": openai_key\n",
        "}\n",
        "\n",
        "client = weaviate.connect_to_embedded(headers=headers)"
      ],
      "metadata": {
        "id": "gFwUpSXl_15o",
        "outputId": "edef5923-dee6-4315-b326-1659f2affbf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 2755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "\n",
        "client.collections.create(\n",
        "    name=\"TestVectorizer\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ],\n",
        "    vectorizer_config=[\n",
        "        Configure.NamedVectors.text2vec_cohere(\n",
        "            name=\"maintext_vector\",\n",
        "            source_properties=[\"maintext\"]\n",
        "        )\n",
        "    ],\n",
        "    generative_config=Configure.Generative.openai(model=\"gpt-4\") # added generation module\n",
        ")"
      ],
      "metadata": {
        "id": "z1eqnNCPBGOo",
        "outputId": "bbfe82d8-7770-451e-def3-2b5e2bef829a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x78edc872b110>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestVectorizer\")\n",
        "for doc in articles:\n",
        "    documents.data.insert({\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"title\": doc[\"title\"],\n",
        "        \"source\": doc[\"source\"],\n",
        "        \"date\": datetime.strptime(doc[\"date\"], \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "        }) # here weaviate performs the vectorization"
      ],
      "metadata": {
        "id": "AXmTMLjjBRcH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.generate.near_text(\n",
        "    query=\"sport\",  # The model provider integration will automatically vectorize the query\n",
        "    single_prompt=\"Write a short summary of maximum 100 characters in Italian of {maintext}\",\n",
        "    limit=2 # apply LLM to the top 2 results\n",
        ")\n",
        "\n",
        "for obj in response.objects:\n",
        "    print(obj.properties[\"title\"])\n",
        "    print(f\"Generated output: {obj.generated}\")  # Note that the generated output is per object\n",
        "    print(\"====================================================\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "03LrtcpKBVgT",
        "outputId": "5b18cd7e-8ca5-4e61-9491-6d273767af82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leclerc dedicates win to Hubert\n",
            "Generated output: Charles Leclerc ha ottenuto la sua prima vittoria in Formula Uno al Gran Premio del Belgio, dedicandola all'amico Anthoine Hubert, morto in un incidente.\n",
            "====================================================\n",
            "\n",
            "Gunman opens fire on car just metres from scene of Hamid Sanambar murder\n",
            "Generated output: La polizia cerca un uomo armato che ha sparato su un'auto a Dublino, vicino al luogo dove Hamid Sanambar è stato ucciso.\n",
            "====================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GENERATIVE AI with an external COHERE**\n",
        "\n",
        "The code above implements RAG using an external LLM module (OpenAI), invoked via the internal Weaviate module. We can also implement a RAG by calling the LLM directly, by using Cohere to implement the vectorization (inside Weaviate) and the generation (direcly with an API call). This way we do not need to pay for an OpenAI API key."
      ],
      "metadata": {
        "id": "qT10gpOzk1pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "HcS0hAhmCysG",
        "outputId": "6984aa2b-0297-442d-dd7c-b155dc6e1cf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.14.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.10.6)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Downloading cohere-5.14.0-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.14.0 fastavro-1.10.0 httpx-sse-0.4.0 types-requests-2.32.0.20250328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hybrid search: 'race'\")\n",
        "response = documents.query.hybrid(query=\"race\", alpha=0.5, return_metadata=MetadataQuery(score=True, explain_score=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} [{}]\".format(round(o.metadata.score*100)/100, o.properties[\"title\"],  o.metadata.explain_score.strip().replace(\"\\n\", '')))"
      ],
      "metadata": {
        "id": "tFaZRSUxDPag",
        "outputId": "08766701-8386-4f46-fcfb-adbda552578e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hybrid search: 'race'\n",
            "0.6 - Conte: 'Chelsea are not in the race to sign Sanchez' [Hybrid (Result Set keyword,bm25) Document b638691f-f4a9-451f-828d-40c067abf5b1: original score 1.1806082, normalized score: 0.5 - Hybrid (Result Set vector,hybridVector) Document b638691f-f4a9-451f-828d-40c067abf5b1: original score 0.312536, normalized score: 0.10020684]\n",
            "0.5 - Leclerc dedicates win to Hubert [Hybrid (Result Set keyword,bm25) Document 0609cc53-0161-4400-bd16-457501fa166b: original score 0.46220398, normalized score: 0 - Hybrid (Result Set vector,hybridVector) Document 0609cc53-0161-4400-bd16-457501fa166b: original score 0.39785844, normalized score: 0.5]\n",
            "0.46 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder [Hybrid (Result Set vector,hybridVector) Document 511f7d15-ac19-49bf-b6e9-f6a7fbb87f43: original score 0.38974845, normalized score: 0.46199924]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "\n",
        "co = cohere.ClientV2(api_key=cohere_key)\n",
        "res = co.chat(\n",
        "    model=\"command-r-plus-08-2024\", # this is a cohere model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a short summary (100 characters at max), in Italian of the textual article \\\n",
        "            provided below: \\n\\n {}\".format(response.objects[1].properties[\"maintext\"]),\n",
        "        } # response includes all the results returned by the previous hybrid query, we take the [1]\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(res.message.content[0].text)"
      ],
      "metadata": {
        "id": "TSQQHbw0C_7m",
        "outputId": "885b47d2-66a5-422e-db9a-ab51ca17bc0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charles Leclerc vince il Gran Premio del Belgio, dedicando la vittoria ad Anthoine Hubert, suo amico scomparso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = co.chat(\n",
        "    model=\"command-r-plus-08-2024\", # this is a cohere model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a one sentence summary in French of the textual article \\\n",
        "            provided below: \\n\\n {}\".format(response.objects[0].properties[\"maintext\"]),\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(res.message.content[0].text)"
      ],
      "metadata": {
        "id": "Py3ubN7h5AL2",
        "outputId": "f6cfb807-9a6c-4150-99a7-67dc8e36f40b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonio Conte, entraîneur de Chelsea, a déclaré qu'il ne pensait pas que le club était en lice pour signer Alexis Sanchez, l'attaquant d'Arsenal, et a refusé de discuter du marché des transferts, laissant les décisions de recrutement au club.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BRING YOUR OWN VECTORS**\n",
        "\n",
        "In the case you have your own vectors, then you can use Weaviare as a vectorDB"
      ],
      "metadata": {
        "id": "CkyAfNjKRK8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "\n",
        "client.collections.create(\n",
        "    name=\"TestOwnVectors\",\n",
        "\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ],\n",
        "\n",
        "    vectorizer_config=wc.Configure.Vectorizer.none(), # no vectorizer\n",
        "\n",
        "    vector_index_config=Configure.VectorIndex.hnsw(\n",
        "\n",
        "        # Distance metric\n",
        "        #distance_metric=wc.VectorDistances.COSINE,\n",
        "        distance_metric=wc.VectorDistances.L2_SQUARED,\n",
        "\n",
        "        # Parameters for HNSW index construction\n",
        "        #ef_construction=256,    # Dynamic list size during construction\n",
        "        #max_connections=128,    # Maximum number of connections per node\n",
        "        #quantizer=Configure.VectorIndex.Quantizer.bq(), # Quantizer configuration\n",
        "        # Parameters for HNSW search\n",
        "        #ef=-1,                  # Dynamic list size during search; -1 enables dynamic Ef\n",
        "        #dynamic_ef_factor=15,   # Multiplier for dynamic Ef\n",
        "        #dynamic_ef_min=200,     # Minimum threshold for dynamic Ef\n",
        "        #dynamic_ef_max=1000,    # Maximum threshold for dynamic Ef\n",
        "    )\n",
        ")\n",
        "\n",
        "documents = client.collections.get(\"TestOwnVectors\")\n",
        "for i, doc in enumerate(articles):\n",
        "    documents.data.insert(\n",
        "        {\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"title\": doc[\"title\"]\n",
        "        },\n",
        "        vector=[i] * 2\n",
        "        )"
      ],
      "metadata": {
        "id": "NYAjyJc9RSW-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If using named vectors, you can specify ones to include e.g. ['title', 'body'], or True to include all\n",
        "for item in documents.iterator( include_vector=True ):\n",
        "    print(json.dumps(item.properties, indent=2))\n",
        "    print(item.vector)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "a4Zv-zkic_bc",
        "outputId": "66d774f1-b3a6-4a0a-c458-93d996c75f0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"maintext\": \"Charles Leclerc\\nCharles Leclerc registered the maiden win of his Formula One career after romping to victory at the Belgian Grand Prix.\\nLess than 24 hours after Leclerc's French motor racing contemporary, Anthoine Hubert, was killed at the Spa-Francorchamps venue, the young Monegasque driver delivered a dominant display to take the chequered flag in his friend's honour.\\nLewis Hamilton finished second after fighting his way past Sebastian Vettel with 12 laps remaining.\\nHamilton's Mercedes team-mate Valtteri Bottas also managed to see off Vettel after the Ferrari driver was forced to make an additional stop for tyres.\\nHamilton extended his lead over Bottas in the championship to 65 points.\\n\\\"This one is for Anthoine,\\\" said an emotional Leclerc on the radio.\\n\\\"It feels good but it is difficult to enjoy a weekend like this.\\n\\\"On one hand I have realised a dream, but on the other hand it has been a difficult weekend.\\n\\\"I have lost a friend, so I would like to dedicate my win to him.\\n\\\"We have grown up together. It is a shame what happened yesterday, so I cannot enjoy my first victory.\\\"\\nLeclerc posted a childhood picture with his arm around Hubert upon news of his death following a horrifying 257kmh crash in Saturday's Formula Two race.\\nHe accompanied the picture with the words: \\\"I can't believe it.\\\"\\nThe Ferrari driver, who is 22 next month, the same age as Hubert, was visibly moved by the tragedy.\\nPrior to the race, he hugged Hubert's mother, Nathalie.\\nA moment of silence was observed before the race in the French driver's memory. Nathalie held her son's pink and white crash helmet. Hubert's brother, Victhor, stood alongside her as the Formula One and grieving Formula Two drivers formed an arc, bowing their heads in honour of their fallen colleague.\\nAll 20 of the drivers' cars yesterday were adorned with \\\"Racing for Anthoine\\\" stickers.\",\n",
            "  \"date\": null,\n",
            "  \"title\": \"Leclerc dedicates win to Hubert\",\n",
            "  \"source\": null\n",
            "}\n",
            "{'default': [4.0, 4.0]}\n",
            "\n",
            "\n",
            "{\n",
            "  \"maintext\": \"Luke O'Reilly with his mother Janet O'Brien Luke O'Reilly Jack Hall Ellis The Metro One Bar in Tallaght, where Hall Ellis had earlier accused Luke O'Reilly of talking to his girlfriend\\nThe mother of a young Dublin man who lost his life following a one-punch attack hopes the sentence her son's killer was handed down will act as a deterrent for others.\\nJack Hall Ellis (21) was yesterday jailed for five years after pleading guilty to the manslaughter of Luke O'Reilly in Tallaght almost two years ago.\\nHall Ellis, who was on bail at the time over an alleged violent disorder incident, struck the 20-year-old with a single punch, which resulted in Mr O'Reilly hitting his head on the ground and suffering fatal injuries.\\nJudge Melanie Greally remarked that single-punch assaults leading to traumatic brain injuries are recurring on the courts' case load.\\nLast night, Mr O'Reilly's mother, Janet O'Brien, told the Herald she was satisfied the judge recognised that such serious assaults were being carried out regularly.\\n\\\"If he didn't get that punch he would never have hit the ground and died,\\\" Ms O'Brien said.\\nDeterrent\\n\\\"I was pleased the judge recognised the fact that there are so many of these one-punch attacks. I don't know how many I have heard of since Luke, or parents who have got in touch that have been there before me.\\\"\\nMr O'Reilly's mother described the five-year term given to Hall Ellis as \\\"a realistic sentence\\\" and added that, as a result, he would not simply walk away from the killing.\\n\\\"Hopefully it will make people sit up and listen, and they'll think twice. It will act as a deterrent for kids going around trying to act the hard man, because as I said it doesn't make much difference to us now,\\\" she added.\\nOn Halloween night in 2017, Mr O'Reilly was socialising in the Metro One Bar in Tallaght when Hall Ellis approached him and accused Luke of talking to his girlfriend.\\nEarly the following morning, Mr O'Reilly was walking along the Old Blessington Road when he was punched once from behind by Hall Ellis, who had drunk up to 20 shots on the night of the attack.\\nThe victim fell to the ground and hit his head on the concrete pavement. He suffered traumatic brain injuries and tragically passed away 13 days later at Beaumont Hospital.\\nIn a moving victim impact statement, Mr O'Reilly's mother said that her family would never be the same following her son's death.\\n\\\"No family occasion will ever be 100pc joyous again. Every birthday, seasonal holiday or any occasion is just a reminder that Luke's not here to celebrate any of these with us. He should be here,\\\" Ms O'Brien said.\\nShe described how the birth of Luke, just after midnight on August 2, 1997, filled her life with \\\"unconditional love and unimaginable sense of pride\\\" that she would get to rear and guide his life so that he too could one day raise his own family.\\nThis, however, was taken away from Ms O'Brien by what she described as a \\\"cowardly\\\" attack by Hall Ellis.\\n\\\"I don't believe Jack intended the outcome of his actions for Luke to lose his life, but ultimately this was the result of his actions.\\n\\\"I also believe that if Jack had abided by his bail conditions my son would be alive here with us today,\\\" she told the court, in reference to the fact that Hall Ellis had breached a curfew and a bond to keep the peace on the night of the fatal assault.\\nMs O'Brien also described as \\\"gut wrenching\\\" the fact that the accused presented himself to gardai only after he realised that Mr O'Reilly was not expected to survive.\\nShe recalled being informed by medical staff at Beaumont Hospital on the morning of November 13, 2017, that Mr O'Reilly was not going to recover from the assault, and making the decision to donate her son's organs.\\n\\\"I climbed into bed beside him, hugging on to his warm body, never wanting to let go and listening to his beating heart that was now only beating to save someone else's life,\\\" Ms O'Brien said.\\nJudge Greally said that Hall Ellis attributed his actions to anger and drunkenness, having previously heard that he consumed between seven and 10 double Captain Morgans that night.\\nThe court heard the accused had nine previous convictions, eight of which were for road traffic offences and one related to possession of drugs.\\nJudge Greally said she was handed a picture of Luke which she said was a \\\"poignant image\\\" of him in his youth, and that he was a \\\"special young man who was deeply loved by his family\\\".\\nSentencing Hall Ellis, the judge said the aggravating factors included the unprovoked nature of the assault, that he breached bail conditions on the night of the assault, and that even though he observed Luke motionless on the ground, he still decided to leave the scene.\\nShe gave him credit for his early guilty plea, his absence of previous violent conduct and his genuine remorse, before jailing him for seven years with the final two suspended.\",\n",
            "  \"date\": null,\n",
            "  \"title\": \"'One-punch killer's sentence will make others think twice'\",\n",
            "  \"source\": null\n",
            "}\n",
            "{'default': [3.0, 3.0]}\n",
            "\n",
            "\n",
            "{\n",
            "  \"maintext\": \"Hamid Sanambar\\nGardai are hunting for a gunman who opened fire on a car in north Dublin - just metres from where Hamid Sanambar was gunned down last week.\\nEmergency services were alerted to reports of gunfire in Kilmore Road in the Artane area of the capital shortly before 9pm on Wednesday.\\nGardai believe a number of rounds were fired at the car before the gunman and the vehicle fled the scene.\\nFled\\nDetectives investigating the shooting are probing if the gunman interacted with the car driver before he opened fire.\\nIt is understood the gunman fled the area on foot.\\nThe incident happened just a few hundred metres from Kilbarron Avenue where Sanambar (41) was shot dead on Wednesday of last week.\\nGardai said investigations into that shooting are still ongoing.\\n\\\"Gardai are investigating reports of an alleged shooting incident on the Kilmore Road, Artane, Dublin 5,\\\" a spokeswoman said.\\n\\\"The incident occurred on June 5, 2019, at approximately 8.50pm.\\n\\\"No injuries were reported and investigations are ongoing.\\\"\\nThe area has been plagued by a number of gun attacks in recent weeks, including two murders.\\nA third person from the suburb, Sean Little (22), was shot dead in Balbriggan last month.\\nEarlier this week, Justice Minister Charlie Flanagan visited Coolock in north Dublin amid escalating gangland violence.\\nMr Flanagan repeatedly described the youngsters involved in the violence as \\\"losers\\\".\\nHe encouraged young people in the area to \\\"forget about the bling\\\".\\nDRUGS\\n\\\"My message to young people in this area is that there is no future in organised crime or drugs or the associated bling that that brings,\\\" he told the media as he arrived at Coolock Garda Station.\\n\\\"These are losers and I'm calling on the community to work closely with gardai to ensure that the challenge can be surmounted.\\\"\\nThe minister said there were about 100 people are involved in serious crime in the Coolock area.\",\n",
            "  \"date\": null,\n",
            "  \"title\": \"Gunman opens fire on car just metres from scene of Hamid Sanambar murder\",\n",
            "  \"source\": null\n",
            "}\n",
            "{'default': [2.0, 2.0]}\n",
            "\n",
            "\n",
            "{\n",
            "  \"maintext\": \"The revival of supersonic passenger travel, thought to be long dead with the demise of Concorde nearly two decades ago, could be about to take wing as American Airlines has put in an order for 60 aircraft capable of flying at 1.7 times the speed of sound. \\nBoom is a start-up based in Denver, Colorado, whose development of Overture, an ultra-fast successor to Concorde that seats 65 to 88 passengers, is so advanced that it showed off designs at last month's Farnborough air show.\",\n",
            "  \"date\": null,\n",
            "  \"title\": \"American Airlines orders 60 Overture supersonic jets\",\n",
            "  \"source\": null\n",
            "}\n",
            "{'default': [0.0, 0.0]}\n",
            "\n",
            "\n",
            "{\n",
            "  \"maintext\": \"Antonio Conte. Pic: PA\\nHead coach Antonio Conte does not think Chelsea are in the race to sign Arsenal forward Alexis Sanchez.\\nSanchez is out of contract this summer and seemed certain to join Manchester City this month.\\nBut the Premier League leaders on Monday evening decided to end their interest because of the costs involved, with Manchester United in pole position, while there were suggestions the Premier League champions were also in the running.\\nConte last Friday spoke of his admiration for Sanchez and described any potential cut-priced deal for the Chile striker as a great opportunity.\\nThe Italian was evasive when quizzed on Chelsea's interest in the player, taking his usual stance in deferring matters of recruitment to the club.\\nAsked if Chelsea were actively seeking to sign Sanchez, Conte said: \\\"I don't know. I don't think so. I don't know, but I don't think so.\\\"\\nConte, speaking ahead of tonight's FA Cup third-round replay at home to Norwich, was reluctant to discuss the transfer market.\\n\\\"About the transfer market, I prefer to talk to the club, also to give opinions,\\\" he added.\\nPlanned\\n\\\"I repeat: I don't want to give my opinion about the transfer market.\\\"\\nMeanwhile, Daniel Farke says Norwich will have something \\\"special\\\" planned for Chelsea tonight.\\nThe Canaries head to Stamford Bridge on the back holding the Premier League champions to a goalless draw at Carrow Road.\\nFarke's men followed that up with a battling 1-0 win at Sky Bet Championship promotion hopefuls Bristol City, who earned great plaudits for their League Cup efforts against Manchester City.\\nThe German believes Norwich will have a free shot at pulling off a shock result in tonight trip to west London and see the winners at home to Newcastle in round four.\\n\\\"I'm hoping for another brilliant performance against one of the giants, and we'll have a special plan for tomorrow,\\\" Farke said. \\\"Hopefully with a really good performance and, if Chelsea aren't at their very best, then we'll always have a chance.\\n\\\"It will be important to keep as much possession as possible, as we don't want to be running after the ball for 90 minutes - so we have to be brave in our possession and our pressing.\\\"\\nFarke, though, accepts Norwich cannot afford to underestimate the challenge ahead.\\n\\\"They haven't scored for three games so they will be wanting to show they can score, especially in a home match,\\\" the Canaries boss added.\",\n",
            "  \"date\": null,\n",
            "  \"title\": \"Conte: 'Chelsea are not in the race to sign Sanchez'\",\n",
            "  \"source\": null\n",
            "}\n",
            "{'default': [1.0, 1.0]}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#default distance is COSINE, we used the square of L2\n",
        "\n",
        "response = documents.query.near_vector(\n",
        "    near_vector=[1.0,1.0], # your query vector goes here\n",
        "    return_metadata=MetadataQuery(distance=True,explain_score=True)\n",
        ")\n",
        "\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(o.metadata.distance, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "on1MydNRWetq",
        "outputId": "a2eb4c8b-943e-471e-a648-5ca7bc8611cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "2.0 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder\n",
            "2.0 - American Airlines orders 60 Overture supersonic jets\n",
            "8.0 - 'One-punch killer's sentence will make others think twice'\n",
            "18.0 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    }
  ]
}