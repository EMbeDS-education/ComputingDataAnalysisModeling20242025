{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EMbeDS-education/ComputingDataAnalysisModeling20242025/blob/main/ISE/SearchEngineWeaviate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weaviate as a Search Engine"
      ],
      "metadata": {
        "id": "euSpBGPyWT2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##################### TO START\n",
        "\n",
        "Please download your COHERE key to vectorize texts from\n",
        "\n",
        "https://dashboard.cohere.com/api-keys.\n",
        "\n",
        "Then load your key in the \"secrets\" of Colab, here to the left, by clicking on the key icon, and storing as \"COHERE_APIKEY\".\n",
        "\n",
        "You find all the documentation of Weaviate in:\n",
        "\n",
        "https://weaviate.io/developers/weaviate\n",
        "\n",
        "###########################################################"
      ],
      "metadata": {
        "id": "qPZG5m1mBNBo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehWhrBsKVeaI",
        "outputId": "22ea965f-b61a-47c3-d940-b4150da73c8c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.11.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.28.1)\n",
            "Collecting validators==0.34.0 (from weaviate-client)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (2.10.6)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.71.0)\n",
            "Collecting grpcio-tools<2.0.0,>=1.66.2 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.71.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.11/dist-packages (from grpcio-health-checking<2.0.0,>=1.66.2->weaviate-client) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools<2.0.0,>=1.66.2->weaviate-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\n",
            "Downloading weaviate_client-4.11.3-py3-none-any.whl (353 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.9/353.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.71.0-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, grpcio-tools, grpcio-health-checking, authlib, weaviate-client\n",
            "Successfully installed authlib-1.3.1 grpcio-health-checking-1.71.0 grpcio-tools-1.71.0 validators-0.34.0 weaviate-client-4.11.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U weaviate-client\n",
        "import weaviate\n",
        "import weaviate.classes.config as wc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Weaviate client\n",
        "\n",
        "import weaviate\n",
        "from weaviate.classes.query import MetadataQuery\n",
        "from weaviate.classes.config import Configure, Property, DataType, Tokenization\n",
        "from weaviate.classes.query import Filter\n",
        "\n",
        "client = weaviate.connect_to_embedded()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfAKTpq7ZEvq",
        "outputId": "826dc926-a455-4f15-d6e0-5da149a2eff1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Binary /root/.cache/weaviate-embedded did not exist. Downloading binary from https://github.com/weaviate/weaviate/releases/download/v1.26.6/weaviate-v1.26.6-Linux-amd64.tar.gz\n",
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/EMbeDS-education/ComputingDataAnalysisModeling20242025/refs/heads/main/ISE/data/5articles.json\n",
        "import json\n",
        "\n",
        "with open(\"5articles.json\", 'r') as f:\n",
        "  articles = json.load(f)\n",
        "\n",
        "articles[0]"
      ],
      "metadata": {
        "id": "CM6M1Nk4iJaM",
        "outputId": "f3ecfae5-3526-49a4-b416-c6fa5ffc7706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-30 10:19:12--  https://raw.githubusercontent.com/EMbeDS-education/ComputingDataAnalysisModeling20242025/refs/heads/main/ISE/data/5articles.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12566 (12K) [text/plain]\n",
            "Saving to: ‘5articles.json’\n",
            "\n",
            "5articles.json      100%[===================>]  12.27K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-03-30 10:19:13 (4.36 MB/s) - ‘5articles.json’ saved [12566/12566]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'American Airlines orders 60 Overture supersonic jets',\n",
              " 'maintext': \"The revival of supersonic passenger travel, thought to be long dead with the demise of Concorde nearly two decades ago, could be about to take wing as American Airlines has put in an order for 60 aircraft capable of flying at 1.7 times the speed of sound. \\nBoom is a start-up based in Denver, Colorado, whose development of Overture, an ultra-fast successor to Concorde that seats 65 to 88 passengers, is so advanced that it showed off designs at last month's Farnborough air show.\",\n",
              " 'date': '2022-08-18',\n",
              " 'source': 'The New York Times'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a simple collection that has two fields of type TEXT and call it \"TestCollection\".\n",
        "\n",
        "**TOKENIZATION OPTIONS**\n",
        "* word: alphanumeric, lowercased tokens, with stopwords filtering (default tokenizer for Weaviate)\n",
        "* lowercase: lowercased tokens\n",
        "* whitespace: whitespace-separated, case-sensitive tokens\n",
        "* field: the entire value of the property is treated as a single token"
      ],
      "metadata": {
        "id": "IOwPipiL2Hu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[All property types](https://weaviate.io/developers/weaviate/config-refs/datatypes)"
      ],
      "metadata": {
        "id": "CY_I5yrgGBzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.create(\n",
        "    name=\"TestCollection\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Just typing \"wc.DataType.\" you can explore other data types..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgtV0ZcfaFLK",
        "outputId": "e68cb281-5892-4808-8f09-38e04711332f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x78bd8e35fc10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATE A TEST COLLECTION**\n",
        "\n",
        "Now we create the collection of name \"TestCollection\" and we insert the \"articles\" in it"
      ],
      "metadata": {
        "id": "iG_xXKqf8ADR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timezone, datetime\n",
        "\n",
        "documents = client.collections.get(\"TestCollection\")\n",
        "\n",
        "for doc in articles:\n",
        "    documents.data.insert({\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"title\": doc[\"title\"],\n",
        "        \"source\": doc[\"source\"],\n",
        "        \"date\": datetime.strptime(doc[\"date\"], \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "sXQi9K3peTUr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ITERATE over all documents in the collection**\n",
        "\n",
        "Notice that it is a \"map\" so that the listing is not necessarily in the order in which they have been inserted"
      ],
      "metadata": {
        "id": "uGS1C5Be8Dk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the elements\n",
        "for i, doc in enumerate(documents.iterator()):\n",
        "  print(doc.uuid, \" - \", doc.properties[\"title\"], \" - \", doc.properties[\"source\"], \" - \", doc.properties[\"date\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGxnrxb4eVou",
        "outputId": "3317b18b-cb65-421c-b376-d6bf73bfb4f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08e7b87c-9efe-4ce7-8955-72597994183b  -  American Airlines orders 60 Overture supersonic jets  -  The New York Times  -  2022-08-18 00:00:00+00:00\n",
            "3d47b085-3443-49ec-a9a8-e75aeb28f1f9  -  Conte: 'Chelsea are not in the race to sign Sanchez'  -  The Herald-ir  -  2018-01-23 00:00:00+00:00\n",
            "4e469733-6886-4ca5-aa9d-5d1f905511ec  -  Leclerc dedicates win to Hubert  -  The Herald-ir  -  2019-09-01 00:00:00+00:00\n",
            "c3322855-11df-4215-a68c-08e52b6941a6  -  'One-punch killer's sentence will make others think twice'  -  The Herald-ir  -  2019-06-29 00:00:00+00:00\n",
            "f03c03ef-e35e-4004-a44b-8ddb170ef96b  -  Gunman opens fire on car just metres from scene of Hamid Sanambar murder  -  The Herald-ir  -  2019-06-07 00:00:00+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUERYING THE COLLECTION**\n",
        "\n",
        "Let's try some simple queries, **bm25** is the sparse vectorization of texts (better than TFIDF) that Weaviate adopts.\n",
        "\n",
        "Notice that it lowercases the parsed tokens, but it does not stem them. This is on the roadmap of features that Weaviate plans to support in the future."
      ],
      "metadata": {
        "id": "KxWBLZ_p8H4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"mother\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "eTcpqOrchF3P",
        "outputId": "c44d258c-5f69-4c4d-c30c-be80e8d130a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44 - 'One-punch killer's sentence will make others think twice'\n",
            "0.24 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_query_results(query, prop_name_to_print, collection):\n",
        "  print(\"QUERY:: {}\\n\".format(query))\n",
        "  response = collection.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "  for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[prop_name_to_print]))"
      ],
      "metadata": {
        "id": "wBdt5xgtnjlQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"mother\", \"title\", documents) # prints the score and the title of the retrieved article"
      ],
      "metadata": {
        "id": "CnyXTXbVmAqG",
        "outputId": "b774820e-7614-478e-b93e-73e44d8c7ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: mother\n",
            "\n",
            "0.44 - 'One-punch killer's sentence will make others think twice'\n",
            "0.24 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"punch\", \"title\", documents) # parsing is induced also by -"
      ],
      "metadata": {
        "id": "AOrhYY5xnFtd",
        "outputId": "09cf7b88-c552-4a6a-9491-6e6ec76bcd5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: punch\n",
            "\n",
            "0.7 - 'One-punch killer's sentence will make others think twice'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"sanchez\", \"title\", documents) # parsing is lowercase"
      ],
      "metadata": {
        "id": "gypOwhconh99",
        "outputId": "a8a4f386-6616-43fa-a820-b2a242dcf3bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: sanchez\n",
            "\n",
            "0.77 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"New\", \"title\", documents) # It is a FIELD parsing, so it does not find \"The New York Times\""
      ],
      "metadata": {
        "id": "ME3EcWKnnM7M",
        "outputId": "c879c391-0d08-489d-8eca-d7d72fe8e0e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: New\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the stopwords are not present by assuming English in field \"maintext\" but they are include in the field \"title\"\n",
        "print_query_results(\"the\", \"title\", documents)"
      ],
      "metadata": {
        "id": "WwXKRsdmoQU7",
        "outputId": "ef41fb99-ae88-4c7b-c29c-13002a11699a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: the\n",
            "\n",
            "0.97 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHANGING STOPWORDS**\n",
        "\n",
        "Say that you now want to consider some words as \"stopwords\", that the system does not consider as such by default\n",
        "\n",
        "documents.config.update(inverted_index_config=wc.Reconfigure.inverted_index(stopwords_additions=[\"victory\"]))\n",
        "\n"
      ],
      "metadata": {
        "id": "5E7rUP8q7zmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEARCH ON A SPECIFIC PROPERTY**"
      ],
      "metadata": {
        "id": "387lhTR4omfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"maintext\"], # this is the line to add\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n",
        "    print(\"query term occurs: \", o.properties[\"maintext\"].count(\"race\"), \"\\n\")"
      ],
      "metadata": {
        "id": "akK8VFJjok6D",
        "outputId": "437529b4-92c9-4a66-bd27-5373415d7536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.64 - Leclerc dedicates win to Hubert\n",
            "query term occurs:  3 \n",
            "\n",
            "0.38 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "query term occurs:  1 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AFTER FIELD BOOSTING**\n",
        "\n",
        "The score is not twice. It applies some normalization and other formulas."
      ],
      "metadata": {
        "id": "XKDIORwYpKAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title^2\", \"maintext\"],\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMXZT4hh9qgy",
        "outputId": "80d73502-ee6b-436f-99b8-b0dbbd34fa5d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.43 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APPLY FIELD FILTERING**"
      ],
      "metadata": {
        "id": "PyTBGhiYqMao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title^2\", \"maintext\"],\n",
        "    filters=Filter.by_property(\"title\").contains_any([\"Leclerc\", \"formula\"]),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "M4i6SecEqQxC",
        "outputId": "641cc654-d045-4420-cfdf-aa5b8cc81d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FILTERING BY DATE or MANY PROPERTIES**"
      ],
      "metadata": {
        "id": "Rgf96h1TrOWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BEFORE FILTERING BY DATE:\\n\")\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n",
        "\n",
        "print(\"\\n\\nAFTER FILTERING BY DATE:\\n\")\n",
        "reference_date = datetime.strptime(\"2018-08-15\", \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    filters=Filter.by_property(\"date\").greater_or_equal(reference_date),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n",
        "\n",
        "\n",
        "print(\"\\n\\nFILTERING MANY PROPERTIES:\\n\")\n",
        "reference_date = datetime.strptime(\"2018-08-15\", \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    filters=( ## use of &, but also |\n",
        "        Filter.by_property(\"date\").greater_or_equal(reference_date) &\n",
        "        Filter.by_property(\"title\").contains_any([\"won\", \"formula\"])\n",
        "        ),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR4i3bKfJ9eJ",
        "outputId": "568d7e0d-8820-44ff-f322-10bc1a11980f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE FILTERING BY DATE:\n",
            "\n",
            "1.18 - Conte: 'Chelsea are not in the race to sign Sanchez' (2018-01-23 00:00:00+00:00)\n",
            "0.46 - Leclerc dedicates win to Hubert (2019-09-01 00:00:00+00:00)\n",
            "\n",
            "\n",
            "AFTER FILTERING BY DATE:\n",
            "\n",
            "0.46 - Leclerc dedicates win to Hubert (2019-09-01 00:00:00+00:00)\n",
            "\n",
            "\n",
            "FILTERING MANY PROPERTIES:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VECTORIZATION:: DENSE EMBEDDINGS**\n",
        "\n",
        "Some advanced features, let's try some vectorized queries. Let's assume we want to find all articles that are \"related to sport\". In this current collection, \"sport\" is not present as a word in any title or maintext."
      ],
      "metadata": {
        "id": "-0oumORCKS3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(query=\"sport\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "uzryepW_KWFV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfortunately, we cannot use all the vectorizer modules that are present in Weaviate.\n",
        "# Here is a list of the ones that are available\n",
        "client.get_meta()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW9aIbtBRG80",
        "outputId": "107725c5-d942-4886-9a09-80d3c12d15c1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hostname': 'http://127.0.0.1:8079',\n",
              " 'modules': {'generative-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "   'name': 'Generative Search - OpenAI'},\n",
              "  'qna-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "   'name': 'OpenAI Question & Answering Module'},\n",
              "  'ref2vec-centroid': {},\n",
              "  'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/',\n",
              "   'name': 'Reranker - Cohere'},\n",
              "  'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/',\n",
              "   'name': 'Cohere Module'},\n",
              "  'text2vec-huggingface': {'documentationHref': 'https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task',\n",
              "   'name': 'Hugging Face Module'},\n",
              "  'text2vec-openai': {'documentationHref': 'https://platform.openai.com/docs/guides/embeddings/what-are-embeddings',\n",
              "   'name': 'OpenAI Module'}},\n",
              " 'version': '1.26.6'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use COHERE as a textual vectorizer [https://dashboard.cohere.com/api-keys](https://dashboard.cohere.com/api-keys). As we can see, using colab we have only a few options for vectorization (openai, cohere, huggingface). Additionally, only one generation model is available (openai).\n",
        "Cohere provides free sample apis. OpenAI does not."
      ],
      "metadata": {
        "id": "2eb-2ivBTN8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## You need first to create a KEY !!!!\n",
        "from google.colab import userdata\n",
        "\n",
        "client.close()\n",
        "cohere_key = userdata.get('COHERE_APIKEY') # MAKE SURE YOU CREATED A KEY\n",
        "headers = {\n",
        "    \"X-Cohere-Api-Key\": cohere_key,\n",
        "}\n",
        "client = weaviate.connect_to_embedded(headers=headers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n67v0q_ETPvy",
        "outputId": "e041ea29-733d-46f6-e767-fd54f0bfade4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 10719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HERE TO CHECK HOW TO INTEGRATE MODELS [https://weaviate.io/developers/weaviate/model-providers](https://weaviate.io/developers/weaviate/model-providers)"
      ],
      "metadata": {
        "id": "Df7kq_CvAljh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "client.collections.create(\n",
        "    name=\"TestVectorizer\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "    ],\n",
        "    vectorizer_config=[\n",
        "        Configure.NamedVectors.text2vec_cohere(\n",
        "            name=\"maintext_vector\",\n",
        "            source_properties=[\"maintext\"],\n",
        "            #model=\"embed-multilingual-light-v3.0\"\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wudqBaSsKtkJ",
        "outputId": "b3684208-e1a7-4a8e-83c6-8d78bb0d4e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x7dee63ad54d0>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXERCISE:** Load 500news.json\n",
        "Index everything in\n",
        "*   maintext (using word tokenizer)\n",
        "*   source (using lowercase tokenizer)\n",
        "*   author (using field tokenizer)\n",
        "\n"
      ],
      "metadata": {
        "id": "j0sdK-fNbuU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.create(\n",
        "    name=\"Test500news\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"author\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "BUqh0iwIe_WC",
        "outputId": "33bf1d70-0a82-4aad-b2a3-7991e82cbf91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x7dee56439710>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/500news.json\n",
        "import json\n",
        "\n",
        "with open(\"500news.json\", 'r') as f:\n",
        "  art500 = json.load(f)"
      ],
      "metadata": {
        "id": "WHynmQFnfL_c",
        "outputId": "b68a1277-0622-4b9d-dada-019b82b70a13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-27 16:43:56--  https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/500news.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147867 (144K) [text/plain]\n",
            "Saving to: ‘500news.json’\n",
            "\n",
            "\r500news.json          0%[                    ]       0  --.-KB/s               \r500news.json        100%[===================>] 144.40K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-03-27 16:43:56 (4.15 MB/s) - ‘500news.json’ saved [147867/147867]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"Test500news\")\n",
        "for doc in art500:\n",
        "    documents.data.insert({\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"source\": doc[\"source\"],\n",
        "        \"author\": doc[\"author\"]\n",
        "    })"
      ],
      "metadata": {
        "id": "8gNJyJNYfThk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create the example collection. Please note that we set here the vectorizer (cohere) and the generation module for an experiment that we will do later (openai, only availabe on the paid model)."
      ],
      "metadata": {
        "id": "e5NKdtCE8d6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestVectorizer\")\n",
        "for doc in articles:\n",
        "    documents.data.insert({\"maintext\": doc[\"maintext\"], \"title\": doc[\"title\"]}) # here weaviate performs the vectorization"
      ],
      "metadata": {
        "id": "c0EG-BXRNqof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'sport'\\n\")\n",
        "response = documents.query.bm25(query=\"sport\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864d907b-8d96-4bf8-b75a-882b2ea3f9f1",
        "id": "e3JPi_1RPNos"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'sport'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure vector search (ordered by increasing distance): 'sport'\\n\")\n",
        "# NOTE THAT WE ALSO NEED THE PARAMETER DISTANCE\n",
        "response = documents.query.near_text(query=\"sport\", return_metadata=MetadataQuery(score=True, distance=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} (score is {})\".format(round(o.metadata.distance*100)/100, o.properties[\"title\"], round(o.metadata.score*100)/100))"
      ],
      "metadata": {
        "id": "eVLWxgqCPNHP",
        "outputId": "8329b8a6-3e26-4c43-d11c-72cf76441b73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure vector search (ordered by increasing distance): 'sport'\n",
            "\n",
            "0.6 - Leclerc dedicates win to Hubert (score is 0.0)\n",
            "0.61 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder (score is 0.0)\n",
            "0.65 - Conte: 'Chelsea are not in the race to sign Sanchez' (score is 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'race'\\n\")\n",
        "response = documents.query.bm25(query=\"race\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4uaK6uMN2Uk",
        "outputId": "fd91a41d-84cc-4b82-9968-7969fe27cd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'race'\n",
            "\n",
            "1.27 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure vector search (ordered by increasing distance): 'race'\\n\")\n",
        "# NOTE THAT WE ALSO NEED THE PARAMETER DISTANCE\n",
        "response = documents.query.near_text(query=\"race\", return_metadata=MetadataQuery(score=True, distance=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} (score is {})\".format(round(o.metadata.distance*100)/100, o.properties[\"title\"], round(o.metadata.score*100)/100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnPc546bOJRn",
        "outputId": "f052db5f-cd6e-4319-eb1d-6db32f97a98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure vector search (ordered by increasing distance): 'race'\n",
            "\n",
            "0.6 - Leclerc dedicates win to Hubert (score is 0.0)\n",
            "0.61 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder (score is 0.0)\n",
            "0.69 - Conte: 'Chelsea are not in the race to sign Sanchez' (score is 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hybrid search (ordered by decreasing score): 'race'\")\n",
        "response = documents.query.hybrid(query=\"race\", alpha=0.5, return_metadata=MetadataQuery(score=True, explain_score=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} [{}]\".format(round(o.metadata.score*100)/100, o.properties[\"title\"],  o.metadata.explain_score.strip().replace(\"\\n\", '')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpWxVaoXRLrh",
        "outputId": "3c1d60a3-3d74-43aa-a032-c7e99a8aaee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hybrid search (ordered by decreasing score): 'race'\n",
            "0.6 - Conte: 'Chelsea are not in the race to sign Sanchez' [Hybrid (Result Set keyword,bm25) Document 6678b75b-3104-45e3-a8d8-302a627c57bf: original score 1.2714014, normalized score: 0.5 - Hybrid (Result Set vector,hybridVector) Document 6678b75b-3104-45e3-a8d8-302a627c57bf: original score 0.31254613, normalized score: 0.10011594]\n",
            "0.5 - Leclerc dedicates win to Hubert [Hybrid (Result Set keyword,bm25) Document c396d041-4307-48f7-ba71-f1bf2bb2c29f: original score 0.5364737, normalized score: 0 - Hybrid (Result Set vector,hybridVector) Document c396d041-4307-48f7-ba71-f1bf2bb2c29f: original score 0.39786047, normalized score: 0.5]\n",
            "0.46 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder [Hybrid (Result Set vector,hybridVector) Document 3a8c833e-6787-4091-ba84-604b4247f01f: original score 0.38975292, normalized score: 0.46199843]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Description of how scoring works](https://weaviate.io/developers/weaviate/concepts/search/hybrid-search)"
      ],
      "metadata": {
        "id": "ivXz0Sg1K9FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A new method, RAG\n",
        "RAG stands for Retrieval Augmented Generation. This is a recent trend in Information Retrieval that aims at reducing the problem of \"hallucinations\" for Large Language Model generation, and returns better answers based on local document archives.\n",
        "- Traditional queries go as follows: the user makes a query to a search engine; the search engine returns, in some predefined format, the answer to that query.\n",
        "- LLM queries: the user makes a query to a Large Language Model (LLM); the LLM creates an answer based on the (often unspecified) training data that was originally used to train it. The LLM often hallucinates, returing wrong answers.\n",
        "- RAG: the user makes a query to a search engine; the search engine runs the query and gets its results. Before returning the results to the user, they are sent to a LLM to \"process\" and generate a textual response that is more convenient to read for the user, but (ideally) does not contain hallucinated information because they use precomputed (retrieved) results."
      ],
      "metadata": {
        "id": "6TXPYna2acie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://weaviate.io/developers/weaviate/model-providers"
      ],
      "metadata": {
        "id": "LNdJHCnjxWRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try to include some generative AI prompts to this query (let's add context to the entities in the news, or let's translate them in Italian).\n",
        "Note that this query will only work for those who have an openai paid module."
      ],
      "metadata": {
        "id": "EpjAkCt1SXmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.close()\n",
        "cohere_key = userdata.get('COHERE_KEY')\n",
        "openai_key = userdata.get(\"OPENAI_KEY2\")\n",
        "headers = {\n",
        "    \"X-Cohere-Api-Key\": cohere_key,\n",
        "    \"X-OpenAI-Api-Key\": openai_key\n",
        "}\n",
        "client = weaviate.connect_to_embedded(headers=headers)"
      ],
      "metadata": {
        "id": "gFwUpSXl_15o",
        "outputId": "e90f592a-8481-42ce-c971-b1c0bab89c83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 41689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "client.collections.create(\n",
        "    name=\"TestVectorizer\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "    ],\n",
        "    vectorizer_config=[\n",
        "        Configure.NamedVectors.text2vec_cohere(\n",
        "            name=\"maintext_vector\",\n",
        "            source_properties=[\"maintext\"],\n",
        "            #model=\"embed-multilingual-light-v3.0\"\n",
        "        )\n",
        "    ],\n",
        "    generative_config=Configure.Generative.openai(model=\"gpt-4\") # added generation module\n",
        ")"
      ],
      "metadata": {
        "id": "z1eqnNCPBGOo",
        "outputId": "08851931-a8e8-4327-e544-c89516b11c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x7dee56429d50>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestVectorizer\")\n",
        "for doc in articles:\n",
        "    documents.data.insert({\"maintext\": doc[\"maintext\"], \"title\": doc[\"title\"]}) # here weaviate performs the vectorization"
      ],
      "metadata": {
        "id": "AXmTMLjjBRcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.generate.near_text(\n",
        "    query=\"sport\",  # The model provider integration will automatically vectorize the query\n",
        "    single_prompt=\"Write a short summary of maximum 100 characters in Italian of {maintext}\",\n",
        "    limit=2 # apply LLM to the top 2 results\n",
        ")"
      ],
      "metadata": {
        "id": "03LrtcpKBVgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in response.objects:\n",
        "    print(obj.properties[\"title\"])\n",
        "    print(f\"Generated output: {obj.generated}\")  # Note that the generated output is per object\n",
        "    print(\"====================================================\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "ZuUsQBXRZpxA",
        "outputId": "03ddcbb4-71b8-4d10-dd5c-5e8442ef3cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leclerc dedicates win to Hubert\n",
            "Generated output: Charles Leclerc ha ottenuto la sua prima vittoria in Formula Uno al Gran Premio del Belgio, dedicandola ad Anthoine Hubert.\n",
            "====================================================\n",
            "\n",
            "Gunman opens fire on car just metres from scene of Hamid Sanambar murder\n",
            "Generated output: La polizia cerca un uomo armato che ha sparato su un'auto a Dublino, vicino al luogo dove Hamid Sanambar è stato ucciso.\n",
            "====================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above implements RAG using an external LLM module (OpenAI), invoked via the internal Weaviate module. We can also implement a RAG by calling the LLM directly, by using Cohere to implement the vectorization (inside Weaviate) and the generation (direcly with an API call). This way we do not need to pay for an OpenAI API key."
      ],
      "metadata": {
        "id": "qT10gpOzk1pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "HcS0hAhmCysG",
        "outputId": "6442210a-3ca7-4fc9-fa95-6913275dae35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.14.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.10.6)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20250306-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Downloading cohere-5.14.0-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250306-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.14.0 fastavro-1.10.0 httpx-sse-0.4.0 types-requests-2.32.0.20250306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hybrid search: 'race'\")\n",
        "response = documents.query.hybrid(query=\"race\", alpha=0.5, return_metadata=MetadataQuery(score=True, explain_score=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} [{}]\".format(round(o.metadata.score*100)/100, o.properties[\"title\"],  o.metadata.explain_score.strip().replace(\"\\n\", '')))"
      ],
      "metadata": {
        "id": "tFaZRSUxDPag",
        "outputId": "4355708b-78e0-4e73-c162-e21eb582e342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hybrid search: 'race'\n",
            "0.6 - Conte: 'Chelsea are not in the race to sign Sanchez' [Hybrid (Result Set keyword,bm25) Document 96804a56-e56d-4959-89a6-94a865a8335d: original score 1.2714014, normalized score: 0.5 - Hybrid (Result Set vector,hybridVector) Document 96804a56-e56d-4959-89a6-94a865a8335d: original score 0.31205738, normalized score: 0.09897505]\n",
            "0.5 - Leclerc dedicates win to Hubert [Hybrid (Result Set keyword,bm25) Document 76486655-ce5a-4aee-9325-d12e7231804a: original score 0.5364737, normalized score: 0 - Hybrid (Result Set vector,hybridVector) Document 76486655-ce5a-4aee-9325-d12e7231804a: original score 0.39708614, normalized score: 0.5]\n",
            "0.46 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder [Hybrid (Result Set vector,hybridVector) Document 1331788c-20cd-4e93-a320-d643a7dbfb60: original score 0.3893391, normalized score: 0.46346223]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "\n",
        "co = cohere.ClientV2(api_key=cohere_key)\n",
        "res = co.chat(\n",
        "    model=\"command-r-plus-08-2024\", # this is a cohere model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a short summary (100 characters at max), in Italian of the textual article \\\n",
        "            provided below: \\n\\n {}\".format(response.objects[1].properties[\"maintext\"]),\n",
        "        } # response includes all the results returned by the previous hybrid query\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(res.message.content[0].text)"
      ],
      "metadata": {
        "id": "TSQQHbw0C_7m",
        "outputId": "6a04b28e-fec4-46e1-b5a7-1f814b144e6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charles Leclerc vince il Gran Premio del Belgio, dedicando la vittoria ad Anthoine Hubert, suo amico scomparso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXERCISE**:\n",
        "Given the bm25 purely textual query with \"race\", provide a \"one-sentence\" summary in French of the maintext of the top article."
      ],
      "metadata": {
        "id": "8UHEwX4D1k5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'race'\\n\")\n",
        "response = documents.query.bm25(query=\"race\", return_metadata=MetadataQuery(score=True), limit=1)\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "y67bwnvn46oi",
        "outputId": "47a02b59-86fc-41c0-fe2b-c40f8b6a3bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'race'\n",
            "\n",
            "1.27 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = co.chat(\n",
        "    model=\"command-r-plus-08-2024\", # this is a cohere model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a one sentence summary in French of the textual article \\\n",
        "            provided below: \\n\\n {}\".format(response.objects[0].properties[\"maintext\"]),\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(res.message.content[0].text)"
      ],
      "metadata": {
        "id": "Py3ubN7h5AL2",
        "outputId": "801d38e9-5b74-49b8-dee5-c5c15fa51048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonio Conte, l'entraîneur de Chelsea, a déclaré qu'il ne pensait pas que son club était en lice pour signer Alexis Sanchez, l'attaquant d'Arsenal, et a évité de discuter du marché des transferts, préférant laisser ces questions au club.\n"
          ]
        }
      ]
    }
  ]
}