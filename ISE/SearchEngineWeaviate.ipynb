{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EMbeDS-education/ComputingDataAnalysisModeling20242025/blob/main/ISE/SearchEngineWeaviate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weaviate as a Search Engine"
      ],
      "metadata": {
        "id": "euSpBGPyWT2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##################### TO START\n",
        "\n",
        "Please download your COHERE key to vectorize texts from\n",
        "\n",
        "https://dashboard.cohere.com/api-keys.\n",
        "\n",
        "Then load your key in the \"secrets\" of Colab, here to the left, by clicking on the key icon, and storing as \"COHERE_APIKEY\".\n",
        "\n",
        "You find all the documentation of Weaviate in:\n",
        "\n",
        "https://weaviate.io/developers/weaviate\n",
        "\n",
        "###########################################################"
      ],
      "metadata": {
        "id": "qPZG5m1mBNBo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehWhrBsKVeaI",
        "outputId": "5570822a-65a3-4688-b000-c3d349a0f159",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: weaviate-client in /usr/local/lib/python3.11/dist-packages (4.11.3)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.28.1)\n",
            "Requirement already satisfied: validators==0.34.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.34.0)\n",
            "Requirement already satisfied: authlib<1.3.2,>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (2.10.6)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.71.0)\n",
            "Requirement already satisfied: grpcio-tools<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.71.0)\n",
            "Requirement already satisfied: grpcio-health-checking<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.71.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.11/dist-packages (from grpcio-health-checking<2.0.0,>=1.66.2->weaviate-client) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools<2.0.0,>=1.66.2->weaviate-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U weaviate-client\n",
        "import weaviate\n",
        "import weaviate.classes.config as wc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Weaviate client\n",
        "\n",
        "import weaviate\n",
        "from weaviate.classes.query import MetadataQuery\n",
        "from weaviate.classes.config import Configure, Property, DataType, Tokenization\n",
        "from weaviate.classes.query import Filter\n",
        "\n",
        "client = weaviate.connect_to_embedded()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfAKTpq7ZEvq",
        "outputId": "55555123-befd-4c15-c301-26a888a8926a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Binary /root/.cache/weaviate-embedded did not exist. Downloading binary from https://github.com/weaviate/weaviate/releases/download/v1.26.6/weaviate-v1.26.6-Linux-amd64.tar.gz\n",
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 2302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/EMbeDS-education/ComputingDataAnalysisModeling20242025/refs/heads/main/ISE/data/5articles.json\n",
        "import json\n",
        "\n",
        "with open(\"5articles.json\", 'r') as f:\n",
        "  articles = json.load(f)\n",
        "\n",
        "articles[0]"
      ],
      "metadata": {
        "id": "CM6M1Nk4iJaM",
        "outputId": "aaa45291-5381-49a5-93c2-16eedd87e7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-30 12:58:26--  https://raw.githubusercontent.com/EMbeDS-education/ComputingDataAnalysisModeling20242025/refs/heads/main/ISE/data/5articles.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12566 (12K) [text/plain]\n",
            "Saving to: ‘5articles.json’\n",
            "\n",
            "5articles.json      100%[===================>]  12.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-30 12:58:27 (31.5 MB/s) - ‘5articles.json’ saved [12566/12566]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'American Airlines orders 60 Overture supersonic jets',\n",
              " 'maintext': \"The revival of supersonic passenger travel, thought to be long dead with the demise of Concorde nearly two decades ago, could be about to take wing as American Airlines has put in an order for 60 aircraft capable of flying at 1.7 times the speed of sound. \\nBoom is a start-up based in Denver, Colorado, whose development of Overture, an ultra-fast successor to Concorde that seats 65 to 88 passengers, is so advanced that it showed off designs at last month's Farnborough air show.\",\n",
              " 'date': '2022-08-18',\n",
              " 'source': 'The New York Times'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a simple collection that has two fields of type TEXT and call it \"TestCollection\".\n",
        "\n",
        "**TOKENIZATION OPTIONS**\n",
        "* word: alphanumeric, lowercased tokens, with stopwords filtering (default tokenizer for Weaviate)\n",
        "* lowercase: lowercased tokens\n",
        "* whitespace: whitespace-separated, case-sensitive tokens\n",
        "* field: the entire value of the property is treated as a single token"
      ],
      "metadata": {
        "id": "IOwPipiL2Hu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[All property types](https://weaviate.io/developers/weaviate/config-refs/datatypes)"
      ],
      "metadata": {
        "id": "CY_I5yrgGBzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all() # To remove anything created before, if any\n",
        "\n",
        "client.collections.create(\n",
        "    name=\"TestCollection\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Just typing \"wc.DataType.\" you can explore other data types..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgtV0ZcfaFLK",
        "outputId": "8244fa8e-3171-4655-8787-42fb2061f8f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x7cff09a76b50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATE A TEST COLLECTION**\n",
        "\n",
        "Now we create the collection of name \"TestCollection\" and we insert the \"articles\" in it"
      ],
      "metadata": {
        "id": "iG_xXKqf8ADR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timezone, datetime\n",
        "\n",
        "documents = client.collections.get(\"TestCollection\")\n",
        "\n",
        "for doc in articles:\n",
        "    documents.data.insert({\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"title\": doc[\"title\"],\n",
        "        \"source\": doc[\"source\"],\n",
        "        \"date\": datetime.strptime(doc[\"date\"], \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "sXQi9K3peTUr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ITERATE over all documents in the collection**\n",
        "\n",
        "Notice that it is a \"map\" so that the listing is not necessarily in the order in which they have been inserted"
      ],
      "metadata": {
        "id": "uGS1C5Be8Dk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the elements\n",
        "for i, doc in enumerate(documents.iterator()):\n",
        "  print(doc.uuid, \" - \", doc.properties[\"title\"], \" - \", doc.properties[\"source\"], \" - \", doc.properties[\"date\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGxnrxb4eVou",
        "outputId": "5ad32dc4-eb0e-4e11-f36b-17936762df31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234c4d4c-f7c7-4c06-a3bf-b89fa6152c1b  -  American Airlines orders 60 Overture supersonic jets  -  The New York Times  -  2022-08-18 00:00:00+00:00\n",
            "3663b81b-886e-45af-a4d3-10bfee980dc8  -  'One-punch killer's sentence will make others think twice'  -  The Herald-ir  -  2019-06-29 00:00:00+00:00\n",
            "9c6570f1-036b-4407-9284-ded9c38269e4  -  Leclerc dedicates win to Hubert  -  The Herald-ir  -  2019-09-01 00:00:00+00:00\n",
            "da23c776-c05b-424d-83f5-b8afe65ba18c  -  Conte: 'Chelsea are not in the race to sign Sanchez'  -  The Herald-ir  -  2018-01-23 00:00:00+00:00\n",
            "f71210d6-ff98-468b-8153-33b35747efad  -  Gunman opens fire on car just metres from scene of Hamid Sanambar murder  -  The Herald-ir  -  2019-06-07 00:00:00+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUERYING THE COLLECTION**\n",
        "\n",
        "Let's try some simple queries, **bm25** is the sparse vectorization of texts (better than TFIDF) that Weaviate adopts.\n",
        "\n",
        "Notice that it lowercases the parsed tokens, but it does not stem them. This is on the roadmap of features that Weaviate plans to support in the future."
      ],
      "metadata": {
        "id": "KxWBLZ_p8H4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"race\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n",
        "    print(\"query term occurs: \", o.properties[\"maintext\"].count(\"race\"), \" in maintext and \", o.properties[\"title\"].count(\"race\"), \" in title\\n\")"
      ],
      "metadata": {
        "id": "eTcpqOrchF3P",
        "outputId": "20196830-a5b9-421c-b99b-0879eee1a50c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.18 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "query term occurs:  1  in maintext and  1  in title\n",
            "\n",
            "0.46 - Leclerc dedicates win to Hubert\n",
            "query term occurs:  3  in maintext and  0  in title\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing is induced also by -\n",
        "\n",
        "query = \"punch\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "AOrhYY5xnFtd",
        "outputId": "3f4b063c-a54b-4ea3-95de-09906c5d8bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7 - 'One-punch killer's sentence will make others think twice'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing is lowercase\n",
        "\n",
        "query = \"sanchez\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "gypOwhconh99",
        "outputId": "5027fb76-60b7-4094-de81-b97cf810181e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.77 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It is a FIELD parsing, so it does not find \"The New York Times\" in article on \"American Airlines\"\n",
        "\n",
        "query = \"The\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "ME3EcWKnnM7M",
        "outputId": "54439a06-8d99-497b-bbd4-a2612fc77c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.97 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the stopwords are not present by assuming English in field \"maintext\" but they are include in the field \"title\"\n",
        "\n",
        "query = \"the\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "WwXKRsdmoQU7",
        "outputId": "238070cd-b9d0-41f3-b297-93b6ebb12b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.97 - Conte: 'Chelsea are not in the race to sign Sanchez'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHANGING STOPWORDS**\n",
        "\n",
        "Say that you now want to consider some words as \"stopwords\", that the system does not consider as such by default\n",
        "\n",
        "documents.config.update(inverted_index_config=wc.Reconfigure.inverted_index(stopwords_additions=[\"victory\"]))\n",
        "\n"
      ],
      "metadata": {
        "id": "5E7rUP8q7zmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEARCH ON A SPECIFIC PROPERTY**"
      ],
      "metadata": {
        "id": "387lhTR4omfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# maintext == is tokenized as WORD and thus stopwords are removed (hence, \"will\" is removed)\n",
        "\n",
        "response = documents.query.bm25(\n",
        "    query=\"will\",\n",
        "    query_properties=[\"maintext\"], # this is the line to add\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n",
        ""
      ],
      "metadata": {
        "id": "akK8VFJjok6D"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# title == is tokenized as LOWERCASE and thus stopwords are NOT removed\n",
        "\n",
        "\n",
        "response = documents.query.bm25(\n",
        "    query=\"will\",\n",
        "    query_properties=[\"title\"], # this is the line to add\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n",
        "    print(\"query term occurs: \", o.properties[\"title\"].count(\"will\"), \"\\n\")"
      ],
      "metadata": {
        "id": "03IKciyNKWwn",
        "outputId": "e878b83c-b043-4128-f3b0-ad4152be248a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.65 - 'One-punch killer's sentence will make others think twice'\n",
            "query term occurs:  1 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AFTER FIELD BOOSTING**\n",
        "\n",
        "The score is not twice. It applies some normalization and other formulas."
      ],
      "metadata": {
        "id": "XKDIORwYpKAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BEFORE BOOSTING:\\n\")\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title\", \"maintext\"],\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))\n",
        "\n",
        "print(\"\\n\\nAFTER BOOSTING:\\n\")\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title^2\", \"maintext\"],\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMXZT4hh9qgy",
        "outputId": "96d6f2d1-7f59-4537-bd80-a20ddc815114"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE BOOSTING:\n",
            "\n",
            "1.27 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n",
            "\n",
            "\n",
            "AFTER BOOSTING:\n",
            "\n",
            "1.43 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APPLY FIELD FILTERING**"
      ],
      "metadata": {
        "id": "PyTBGhiYqMao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title^2\", \"maintext\"],\n",
        "    filters=Filter.by_property(\"title\").contains_any([\"Leclerc\", \"formula\"]),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "M4i6SecEqQxC",
        "outputId": "ac8ba576-6706-4e26-dd23-e8f4c30425a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FILTERING BY DATE or MANY PROPERTIES**"
      ],
      "metadata": {
        "id": "Rgf96h1TrOWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BEFORE FILTERING BY DATE:\\n\")\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n",
        "\n",
        "print(\"\\n\\nAFTER FILTERING BY DATE:\\n\")\n",
        "reference_date = datetime.strptime(\"2018-08-15\", \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    filters=Filter.by_property(\"date\").greater_or_equal(reference_date),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n",
        "\n",
        "\n",
        "print(\"\\n\\nAPPLY MANY FILTERS OVER MANY PROPERTIES:\\n\")\n",
        "reference_date = datetime.strptime(\"2018-08-15\", \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    filters=( ## use of &, but also |\n",
        "        Filter.by_property(\"date\").greater_or_equal(reference_date) &\n",
        "        Filter.by_property(\"title\").contains_any([\"won\", \"formula\"])\n",
        "        ),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR4i3bKfJ9eJ",
        "outputId": "1e9bf907-510b-4756-c7b1-2998a3a84dd2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE FILTERING BY DATE:\n",
            "\n",
            "1.18 - Conte: 'Chelsea are not in the race to sign Sanchez' (2018-01-23 00:00:00+00:00)\n",
            "0.46 - Leclerc dedicates win to Hubert (2019-09-01 00:00:00+00:00)\n",
            "\n",
            "\n",
            "AFTER FILTERING BY DATE:\n",
            "\n",
            "0.46 - Leclerc dedicates win to Hubert (2019-09-01 00:00:00+00:00)\n",
            "\n",
            "\n",
            "APPLY MANY FILTERS OVER MANY PROPERTIES:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VECTORIZATION:: DENSE EMBEDDINGS**\n",
        "\n",
        "Some advanced features, let's try some vectorized queries. Let's assume we want to find all articles that are \"related to sport\". In this current collection, \"sport\" is not present as a word in any title or maintext."
      ],
      "metadata": {
        "id": "-0oumORCKS3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The term \"sport\" does not occur and so BM25 does not return any result\n",
        "\n",
        "response = documents.query.bm25(query=\"sport\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "uzryepW_KWFV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfortunately, we cannot use all the vectorizer modules that are present in Weaviate.\n",
        "# Here is a list of the ones that are available\n",
        "client.get_meta()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW9aIbtBRG80",
        "outputId": "ba574e5c-e6dc-4ec0-8932-d08b68dea210"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hostname': 'http://127.0.0.1:8079',\n",
              " 'modules': {'generative-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "   'name': 'Generative Search - OpenAI'},\n",
              "  'qna-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "   'name': 'OpenAI Question & Answering Module'},\n",
              "  'ref2vec-centroid': {},\n",
              "  'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/',\n",
              "   'name': 'Reranker - Cohere'},\n",
              "  'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/',\n",
              "   'name': 'Cohere Module'},\n",
              "  'text2vec-huggingface': {'documentationHref': 'https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task',\n",
              "   'name': 'Hugging Face Module'},\n",
              "  'text2vec-openai': {'documentationHref': 'https://platform.openai.com/docs/guides/embeddings/what-are-embeddings',\n",
              "   'name': 'OpenAI Module'}},\n",
              " 'version': '1.26.6'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use COHERE as a textual vectorizer [https://dashboard.cohere.com/api-keys](https://dashboard.cohere.com/api-keys). As we can see, using colab we have only a few options for vectorization (openai, cohere, huggingface). Additionally, only one generation model is available (openai).\n",
        "Cohere provides free sample apis. OpenAI does not.\n",
        "\n",
        "At this link you find how to integrate MODELS [https://weaviate.io/developers/weaviate/model-providers](https://weaviate.io/developers/weaviate/model-providers)"
      ],
      "metadata": {
        "id": "2eb-2ivBTN8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## You need first to create a KEY !!!!\n",
        "from google.colab import userdata\n",
        "\n",
        "client.close()\n",
        "cohere_key = userdata.get('COHERE_APIKEY') # MAKE SURE YOU CREATED A KEY\n",
        "headers = {\n",
        "    \"X-Cohere-Api-Key\": cohere_key,\n",
        "}\n",
        "client = weaviate.connect_to_embedded(headers=headers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n67v0q_ETPvy",
        "outputId": "4b056973-67c5-4062-86b5-6d711dd29316"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 5532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATE A VECTOR DB**\n"
      ],
      "metadata": {
        "id": "Df7kq_CvAljh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "client.collections.create(\n",
        "    name=\"TestVectorizer\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ],\n",
        "    vectorizer_config=[\n",
        "        Configure.NamedVectors.text2vec_cohere(\n",
        "            name=\"maintext_vector\",\n",
        "            source_properties=[\"maintext\"],\n",
        "            #model=\"embed-multilingual-light-v3.0\"\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wudqBaSsKtkJ",
        "outputId": "2a15da39-672e-4e73-c8ed-d64cfc9155e1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x7cfefc95a410>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timezone, datetime\n",
        "\n",
        "documents = client.collections.get(\"TestVectorizer\")\n",
        "\n",
        "for doc in articles:\n",
        "    documents.data.insert({\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"title\": doc[\"title\"],\n",
        "        \"source\": doc[\"source\"],\n",
        "        \"date\": datetime.strptime(doc[\"date\"], \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "KtFZv0nSMLDO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'sport'\\n\")\n",
        "response = documents.query.bm25(query=\"sport\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2960fdc-d5ae-40dd-883b-6c2f30abf404",
        "id": "e3JPi_1RPNos"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'sport'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure vector search (ordered by increasing distance): 'sport'\\n\")\n",
        "# NOTE THAT WE ALSO NEED THE PARAMETER DISTANCE\n",
        "response = documents.query.near_text(query=\"sport\", return_metadata=MetadataQuery(score=True, distance=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} (score is {})\".format(round(o.metadata.distance*100)/100, o.properties[\"title\"], round(o.metadata.score*100)/100))"
      ],
      "metadata": {
        "id": "eVLWxgqCPNHP",
        "outputId": "c4f7f39d-aa16-4e0e-c09b-387fe27ea1e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure vector search (ordered by increasing distance): 'sport'\n",
            "\n",
            "0.6 - Leclerc dedicates win to Hubert (score is 0.0)\n",
            "0.61 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder (score is 0.0)\n",
            "0.65 - Conte: 'Chelsea are not in the race to sign Sanchez' (score is 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HYBRID SEARCH**\n",
        "\n",
        "Let us consider a query that admits results for both syntactic and vectorized search"
      ],
      "metadata": {
        "id": "YRXiT32tM_Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'race'\\n\")\n",
        "response = documents.query.bm25(query=\"race\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4uaK6uMN2Uk",
        "outputId": "060804e3-ac72-4ac1-f534-16a50bcb8ecb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'race'\n",
            "\n",
            "1.18 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.46 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure vector search (ordered by increasing distance): 'race'\\n\")\n",
        "# NOTE THAT WE ALSO NEED THE PARAMETER DISTANCE\n",
        "response = documents.query.near_text(query=\"race\", return_metadata=MetadataQuery(score=True, distance=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} (score is {})\".format(round(o.metadata.distance*100)/100, o.properties[\"title\"], round(o.metadata.score*100)/100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnPc546bOJRn",
        "outputId": "f052db5f-cd6e-4319-eb1d-6db32f97a98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure vector search (ordered by increasing distance): 'race'\n",
            "\n",
            "0.6 - Leclerc dedicates win to Hubert (score is 0.0)\n",
            "0.61 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder (score is 0.0)\n",
            "0.69 - Conte: 'Chelsea are not in the race to sign Sanchez' (score is 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = syntactic, 1 = vectorized\n",
        "print(\"hybrid search (ordered by decreasing score): 'race'\")\n",
        "response = documents.query.hybrid(query=\"race\", alpha=0.5, return_metadata=MetadataQuery(score=True, explain_score=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} [{}]\".format(round(o.metadata.score*100)/100, o.properties[\"title\"],  o.metadata.explain_score.strip().replace(\"\\n\", '')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpWxVaoXRLrh",
        "outputId": "bf5b1555-3494-41c1-e0d5-6171c35f4cef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hybrid search (ordered by decreasing score): 'race'\n",
            "0.6 - Conte: 'Chelsea are not in the race to sign Sanchez' [Hybrid (Result Set keyword,bm25) Document 8a72ce3c-68e2-4fa3-b99b-359a551dd75d: original score 1.1829562, normalized score: 0.5 - Hybrid (Result Set vector,hybridVector) Document 8a72ce3c-68e2-4fa3-b99b-359a551dd75d: original score 0.31254542, normalized score: 0.100039184]\n",
            "0.5 - Leclerc dedicates win to Hubert [Hybrid (Result Set keyword,bm25) Document 1badb2ce-59fe-4920-9c1f-d9df5242069f: original score 0.46418247, normalized score: 0 - Hybrid (Result Set vector,hybridVector) Document 1badb2ce-59fe-4920-9c1f-d9df5242069f: original score 0.39784843, normalized score: 0.5]\n",
            "0.46 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder [Hybrid (Result Set vector,hybridVector) Document 3ec1bb3f-81e4-4429-a556-2e854e7fd3f0: original score 0.38973743, normalized score: 0.46196988]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Description of how scoring works](https://weaviate.io/developers/weaviate/concepts/search/hybrid-search)"
      ],
      "metadata": {
        "id": "ivXz0Sg1K9FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A new method, RAG\n",
        "\n",
        "RAG stands for Retrieval Augmented Generation. This is a recent trend in Information Retrieval that aims at reducing the problem of \"hallucinations\" for Large Language Model generation, and returns better answers based on local document archives.\n",
        "- Traditional queries go as follows: the user makes a query to a search engine; the search engine returns, in some predefined format, the answer to that query.\n",
        "- LLM queries: the user makes a query to a Large Language Model (LLM); the LLM creates an answer based on the (often unspecified) training data that was originally used to train it. The LLM often hallucinates, returing wrong answers.\n",
        "- RAG: the user makes a query to a search engine; the search engine runs the query and gets its results. Before returning the results to the user, they are sent to a LLM to \"process\" and generate a textual response that is more convenient to read for the user, but (ideally) does not contain hallucinated information because they use precomputed (retrieved) results."
      ],
      "metadata": {
        "id": "6TXPYna2acie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://weaviate.io/developers/weaviate/model-providers"
      ],
      "metadata": {
        "id": "LNdJHCnjxWRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GENERATIVE AI with OPENAI GPT-4**\n",
        "\n",
        "Now let's try to include some generative AI prompts to this query (let's add context to the entities in the news, or let's translate them in Italian).\n",
        "Note that this query will only work for those who have an openai paid module."
      ],
      "metadata": {
        "id": "EpjAkCt1SXmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.close()\n",
        "\n",
        "cohere_key = userdata.get('COHERE_APIKEY')\n",
        "openai_key = userdata.get(\"OPEN_APIKEY2\")\n",
        "headers = {\n",
        "    \"X-Cohere-Api-Key\": cohere_key,\n",
        "    \"X-OpenAI-Api-Key\": openai_key\n",
        "}\n",
        "\n",
        "client = weaviate.connect_to_embedded(headers=headers)"
      ],
      "metadata": {
        "id": "gFwUpSXl_15o",
        "outputId": "3312c691-62c2-4938-8e6d-3ee291156824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 9157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "\n",
        "client.collections.create(\n",
        "    name=\"TestVectorizer\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"source\", data_type=wc.DataType.TEXT, tokenization=Tokenization.FIELD),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ],\n",
        "    vectorizer_config=[\n",
        "        Configure.NamedVectors.text2vec_cohere(\n",
        "            name=\"maintext_vector\",\n",
        "            source_properties=[\"maintext\"],\n",
        "            #model=\"embed-multilingual-light-v3.0\"\n",
        "        )\n",
        "    ],\n",
        "    generative_config=Configure.Generative.openai(model=\"gpt-4\") # added generation module\n",
        ")"
      ],
      "metadata": {
        "id": "z1eqnNCPBGOo",
        "outputId": "fd9f5617-bd6c-4580-a28b-fb2bc10ef6d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x7cff09b19410>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestVectorizer\")\n",
        "for doc in articles:\n",
        "    documents.data.insert({\n",
        "        \"maintext\": doc[\"maintext\"],\n",
        "        \"title\": doc[\"title\"]\n",
        "        }) # here weaviate performs the vectorization"
      ],
      "metadata": {
        "id": "AXmTMLjjBRcH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.generate.near_text(\n",
        "    query=\"sport\",  # The model provider integration will automatically vectorize the query\n",
        "    single_prompt=\"Write a short summary of maximum 100 characters in Italian of {maintext}\",\n",
        "    limit=2 # apply LLM to the top 2 results\n",
        ")"
      ],
      "metadata": {
        "id": "03LrtcpKBVgT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in response.objects:\n",
        "    print(obj.properties[\"title\"])\n",
        "    print(f\"Generated output: {obj.generated}\")  # Note that the generated output is per object\n",
        "    print(\"====================================================\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "ZuUsQBXRZpxA",
        "outputId": "2a082e4d-18a2-4e82-9a75-4b27813874d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leclerc dedicates win to Hubert\n",
            "Generated output: Charles Leclerc ha ottenuto la sua prima vittoria in Formula Uno al Gran Premio del Belgio, dedicandola ad Anthoine Hubert.\n",
            "====================================================\n",
            "\n",
            "Gunman opens fire on car just metres from scene of Hamid Sanambar murder\n",
            "Generated output: La polizia cerca un uomo armato che ha sparato su un'auto a Dublino, vicino al luogo dove Hamid Sanambar è stato ucciso.\n",
            "====================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GENERATIVE AI with an external COHERE**\n",
        "\n",
        "The code above implements RAG using an external LLM module (OpenAI), invoked via the internal Weaviate module. We can also implement a RAG by calling the LLM directly, by using Cohere to implement the vectorization (inside Weaviate) and the generation (direcly with an API call). This way we do not need to pay for an OpenAI API key."
      ],
      "metadata": {
        "id": "qT10gpOzk1pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "HcS0hAhmCysG",
        "outputId": "6d83b0bf-e5e0-4fc7-f8e6-2c829fdd4f72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.14.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.10.6)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Downloading cohere-5.14.0-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.14.0 fastavro-1.10.0 httpx-sse-0.4.0 types-requests-2.32.0.20250328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hybrid search: 'race'\")\n",
        "response = documents.query.hybrid(query=\"race\", alpha=0.5, return_metadata=MetadataQuery(score=True, explain_score=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} [{}]\".format(round(o.metadata.score*100)/100, o.properties[\"title\"],  o.metadata.explain_score.strip().replace(\"\\n\", '')))"
      ],
      "metadata": {
        "id": "tFaZRSUxDPag",
        "outputId": "bd435d57-2671-4b53-f099-d2c2a6b7b6b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hybrid search: 'race'\n",
            "0.6 - Conte: 'Chelsea are not in the race to sign Sanchez' [Hybrid (Result Set keyword,bm25) Document 1fbd403d-8c83-4033-b991-9f302296a2f9: original score 1.1795324, normalized score: 0.5 - Hybrid (Result Set vector,hybridVector) Document 1fbd403d-8c83-4033-b991-9f302296a2f9: original score 0.31253493, normalized score: 0.10006716]\n",
            "0.5 - Leclerc dedicates win to Hubert [Hybrid (Result Set keyword,bm25) Document 4ba90a36-2af6-4c47-b84e-565e5d9b6183: original score 0.46129686, normalized score: 0 - Hybrid (Result Set vector,hybridVector) Document 4ba90a36-2af6-4c47-b84e-565e5d9b6183: original score 0.3978603, normalized score: 0.5]\n",
            "0.46 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder [Hybrid (Result Set vector,hybridVector) Document 85a95143-ed92-4458-ba96-1c614389ae63: original score 0.389758, normalized score: 0.46202332]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "\n",
        "co = cohere.ClientV2(api_key=cohere_key)\n",
        "res = co.chat(\n",
        "    model=\"command-r-plus-08-2024\", # this is a cohere model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a short summary (100 characters at max), in Italian of the textual article \\\n",
        "            provided below: \\n\\n {}\".format(response.objects[1].properties[\"maintext\"]),\n",
        "        } # response includes all the results returned by the previous hybrid query\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(res.message.content[0].text)"
      ],
      "metadata": {
        "id": "TSQQHbw0C_7m",
        "outputId": "fcd14cbb-991c-42e0-e351-95f0698953c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charles Leclerc vince il Gran Premio del Belgio, dedicando la vittoria all'amico Anthoine Hubert, tragicamente scomparso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = co.chat(\n",
        "    model=\"command-r-plus-08-2024\", # this is a cohere model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a one sentence summary in French of the textual article \\\n",
        "            provided below: \\n\\n {}\".format(response.objects[0].properties[\"maintext\"]),\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(res.message.content[0].text)"
      ],
      "metadata": {
        "id": "Py3ubN7h5AL2",
        "outputId": "c61ef1df-99a0-4553-83e5-996ca012b1dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonio Conte, entraîneur de Chelsea, a déclaré qu'il ne pensait pas que le club était en lice pour signer Alexis Sanchez, l'attaquant d'Arsenal, et a évité de discuter du marché des transferts, affirmant qu'il préférait laisser ces questions au club.\n"
          ]
        }
      ]
    }
  ]
}